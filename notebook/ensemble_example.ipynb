{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\cs4248\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from ensemble import EnsembleModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_name = \"jeffnjy/distilbert-base-test\"\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(distilbert_name)\n",
    "distilbert_model = AutoModelForQuestionAnswering.from_pretrained(distilbert_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_name = \"jeffnjy/albert-base-test\"\n",
    "albert_tokenizer = AutoTokenizer.from_pretrained(albert_name)\n",
    "albert_model = AutoModelForQuestionAnswering.from_pretrained(albert_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_name = \"jeffnjy/roberta-base-test\"\n",
    "roberta_tokenizer = RobertaTokenizerFast.from_pretrained(roberta_name)\n",
    "roberta_model = AutoModelForQuestionAnswering.from_pretrained(roberta_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 1.19k/1.19k [00:00<?, ?B/s]\n",
      "d:\\anaconda3\\envs\\cs4248\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\px109\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 24.2MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 712k/712k [00:00<00:00, 3.00MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 125/125 [00:00<?, ?B/s] \n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 673/673 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 436M/436M [00:20<00:00, 21.1MB/s] \n"
     ]
    }
   ],
   "source": [
    "bert_name = \"jeffnjy/bert-base-test\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
    "bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 1.97k/1.97k [00:00<?, ?B/s]\n",
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 798k/798k [00:00<00:00, 845kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.41M/2.41M [00:00<00:00, 8.28MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 346/346 [00:00<00:00, 346kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 931/931 [00:00<00:00, 921kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 467M/467M [00:39<00:00, 11.8MB/s] \n"
     ]
    }
   ],
   "source": [
    "xlnet_name = \"JiayanL/XLNET\"\n",
    "xlnet_tokenizer = AutoTokenizer.from_pretrained(xlnet_name)\n",
    "xlnet_model = AutoModelForQuestionAnswering.from_pretrained(xlnet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight of each model can be changed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = {\n",
    "    \"bert\": 0.2,\n",
    "    \"albert\": 0.4,\n",
    "    \"distilbert\": 0.3,\n",
    "    \"roberta\": 1.0,\n",
    "    \"xlnet\": 0.5,\n",
    "}\n",
    "mode = \"soft\" # soft/hard\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = EnsembleModel(device=device)\n",
    "ensemble_model.add_model(model=bert_model, tokenizer=bert_tokenizer, weight=model_weights[\"bert\"])\n",
    "ensemble_model.add_model(model=albert_model, tokenizer=albert_tokenizer, weight=model_weights[\"albert\"])\n",
    "ensemble_model.add_model(model=distilbert_model, tokenizer=distilbert_tokenizer, weight=model_weights[\"distilbert\"])\n",
    "ensemble_model.add_model(model=roberta_model, tokenizer=roberta_tokenizer, weight=model_weights[\"roberta\"])\n",
    "ensemble_model.add_model(model=xlnet_model, tokenizer=xlnet_tokenizer, weight=model_weights[\"xlnet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Perform perdiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a Perform perdiction on one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which NFL team represented the AFC at Super Bowl 50?\"\n",
    "context = \"\"\"Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) \n",
    "for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football \n",
    "Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February \n",
    "7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the \n",
    "league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the \n",
    "tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl \n",
    "L\"), so that the logo could prominently feature the Arabic numerals 50.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Weighted sum of softmax probabilities (mode=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Denver Broncos'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.predict(question=question, context=context, mode=\"soft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Weighted votes (mode=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Denver Broncos'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.predict(question=question, context=context, mode=\"hard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Perform perdiction on a json dataset and generate a perdiction json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [36:30<00:00,  4.83it/s] \n"
     ]
    }
   ],
   "source": [
    "inpath = \"../dataset/dev-v1.1.json\"\n",
    "outpath = \"../tmp/prediction/ensemble_all_exact.json\"\n",
    "ensemble_model.generate_prediction_json(inpath, outpath, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c Weight search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = [\n",
    "    (0.1, 0.4, 0.2, 1.0, 0.8, \"soft\"),\n",
    "    (0.0, 0.4, 0.0, 1.0, 0.8, \"soft\"),\n",
    "    (0.0, 0.0, 0.0, 1.0, 0.0, \"soft\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [36:10<00:00,  4.87it/s]\n",
      "100%|██████████| 10570/10570 [34:41<00:00,  5.08it/s]\n",
      "100%|██████████| 10570/10570 [34:37<00:00,  5.09it/s]\n",
      "100%|██████████| 10570/10570 [34:34<00:00,  5.10it/s]\n",
      "100%|██████████| 10570/10570 [34:33<00:00,  5.10it/s]\n",
      "100%|██████████| 10570/10570 [34:36<00:00,  5.09it/s]\n",
      "100%|██████████| 10570/10570 [34:41<00:00,  5.08it/s]\n",
      "100%|██████████| 10570/10570 [34:36<00:00,  5.09it/s]\n",
      "100%|██████████| 10570/10570 [34:34<00:00,  5.09it/s]\n"
     ]
    }
   ],
   "source": [
    "inpath = \"../dataset/dev-v1.1.json\"\n",
    "for param in search_params:\n",
    "    x, y, z, w, u, m = param\n",
    "    ensemble_model = EnsembleModel(device=device)\n",
    "    ensemble_model.add_model(model=bert_model, tokenizer=bert_tokenizer, weight=x)\n",
    "    ensemble_model.add_model(model=albert_model, tokenizer=albert_tokenizer, weight=y)\n",
    "    ensemble_model.add_model(model=distilbert_model, tokenizer=distilbert_tokenizer, weight=z)\n",
    "    ensemble_model.add_model(model=roberta_model, tokenizer=roberta_tokenizer, weight=w)\n",
    "    ensemble_model.add_model(model=xlnet_model, tokenizer=xlnet_tokenizer, weight=u)\n",
    "    outpath = f\"../tmp/prediction/ensemble_{x}_{y}_{z}_{w}_{u}_{m}.json\"\n",
    "    ensemble_model.generate_prediction_json(inpath, outpath, m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
